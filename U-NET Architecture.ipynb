
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MANUAL NET ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\LIKHITH\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "\n",
    "import os \n",
    "import glob\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Convolution2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "benign = 'Dataset/benign'\n",
    "malignant = 'Dataset/malignant'\n",
    "normal = 'Dataset/normal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images(item_dir, n=6):\n",
    "    all_item_dir = os.listdir(item_dir)\n",
    "    item_files = [os.path.join(item_dir, file) for file in all_item_dir][:n]\n",
    "    \n",
    "    plt.figure(figsize=(80, 40))\n",
    "    for idx, img_path in enumerate(item_files):\n",
    "        plt.subplot(3, n, idx+1)\n",
    "        img = plt.imread(img_path)\n",
    "        plt.imshow(img, cmap='gray')\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "def image_details_print(data,path):\n",
    "    print('======== Images in: ', path)\n",
    "    for key,values in data.items():\n",
    "        print(key,':\\t', values)\n",
    "\n",
    "\n",
    "def images_details(path):\n",
    "    files=[f for f in glob.glob(path + \"**/*.*\", recursive=True)]\n",
    "    data={}\n",
    "    data['Images_count']=len(files)\n",
    "    data['Min_width']=10**100\n",
    "    data['Max_width']=0\n",
    "    data['Min_height']=10**100\n",
    "    data['Max_height']=0\n",
    "    \n",
    "    for f in files:\n",
    "        img=Image.open(f)\n",
    "        width,height=img.size\n",
    "        data['Min_width']=min(width,data['Min_width'])\n",
    "        data['Max_width']=max(width, data['Max_width'])\n",
    "        data['Min_height']=min(height, data['Min_height'])\n",
    "        data['Max_height']=max(height, data['Max_height'])\n",
    "        \n",
    "    image_details_print(data,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRAINING DATA FOR BENIGN:\n",
      "\n"
     ]
    },
    {
     "ename": "UnidentifiedImageError",
     "evalue": "cannot identify image file 'Dataset\\\\benign\\\\Thumbs.db'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTRAINING DATA FOR BENIGN:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m images_details(benign)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      6\u001b[0m plot_images(benign, \u001b[38;5;241m10\u001b[39m)\n",
      "Cell \u001b[1;32mIn[3], line 30\u001b[0m, in \u001b[0;36mimages_details\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     27\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax_height\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files:\n\u001b[1;32m---> 30\u001b[0m     img\u001b[38;5;241m=\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(f)\n\u001b[0;32m     31\u001b[0m     width,height\u001b[38;5;241m=\u001b[39mimg\u001b[38;5;241m.\u001b[39msize\n\u001b[0;32m     32\u001b[0m     data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin_width\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mmin\u001b[39m(width,data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin_width\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:3186\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   3184\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m message \u001b[38;5;129;01min\u001b[39;00m accept_warnings:\n\u001b[0;32m   3185\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message)\n\u001b[1;32m-> 3186\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m UnidentifiedImageError(\n\u001b[0;32m   3187\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot identify image file \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (filename \u001b[38;5;28;01mif\u001b[39;00m filename \u001b[38;5;28;01melse\u001b[39;00m fp)\n\u001b[0;32m   3188\u001b[0m )\n",
      "\u001b[1;31mUnidentifiedImageError\u001b[0m: cannot identify image file 'Dataset\\\\benign\\\\Thumbs.db'"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(\"TRAINING DATA FOR BENIGN:\")\n",
    "print(\"\")\n",
    "images_details(benign)\n",
    "print(\"\")\n",
    "plot_images(benign, 10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"TRAINING DATA FOR MALIGNANT:\")\n",
    "print(\"\")\n",
    "images_details(malignant)\n",
    "print(\"\")\n",
    "plot_images(malignant, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\")\n",
    "print(\"TRAINING DATA FOR NORMAL:\")\n",
    "print(\"\")\n",
    "images_details(normal)\n",
    "print(\"\")\n",
    "plot_images(normal, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to your dataset directory\n",
    "dataset_dir = 'Dataset'\n",
    "\n",
    "# Set the batch size and number of classes\n",
    "batch_size = 64\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an ImageDataGenerator for data augmentation and preprocessing\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset using the ImageDataGenerator\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator = datagen.flow_from_directory(\n",
    "    dataset_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset='validation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL=Sequential()\n",
    "MODEL.add(Convolution2D(32,(3,3),input_shape=(224,224,3),activation='relu'))\n",
    "MODEL.add(MaxPooling2D(pool_size=(2,2)))\n",
    "MODEL.add(Flatten())\n",
    "MODEL.add(Dense(3, activation='softmax'))\n",
    "MODEL.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = MODEL.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=epochs # Add the callbacks here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def graph():\n",
    "    #Plot training & validation accuracy values\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def graph():\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Test'], loc='upper left')\n",
    "    plt.show()\n",
    "graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
